# -*- coding: utf-8 -*-
"""Face Dectection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WfqilmskFYTHwnR2Wpb-hFK-8j7l_4X2
"""

import cv2
import dlib
import numpy as np
import os
import glob

def ref3DModel():
    modelPoints = [[0.0, 0.0, 0.0],
                   [0.0, -330.0, -65.0],
                   [-225.0, 170.0, -135.0],
                   [225.0, 170.0, -135.0],
                   [-150.0, -150.0, -125.0],
                   [150.0, -150.0, -125.0]]
    return np.array(modelPoints, dtype=np.float64)


def ref2dImagePoints(shape):
    imagePoints = [[shape.part(30).x, shape.part(30).y],
                   [shape.part(8).x, shape.part(8).y],
                   [shape.part(36).x, shape.part(36).y],
                   [shape.part(45).x, shape.part(45).y],
                   [shape.part(48).x, shape.part(48).y],
                   [shape.part(54).x, shape.part(54).y]]
    return np.array(imagePoints, dtype=np.float64)


def CameraMatrix(fl, center):
    cameraMatrix = [[fl, 1, center[0]],
                    [0, fl, center[1]],
                    [0, 0, 1]]
    return np.array(cameraMatrix, dtype=np.float)


def draw(img, shapes):
    drawPolyline(img, shapes, 0, 16)
    drawPolyline(img, shapes, 17, 21)
    drawPolyline(img, shapes, 22, 26)
    drawPolyline(img, shapes, 27, 30)
    drawPolyline(img, shapes, 30, 35, True)
    drawPolyline(img, shapes, 36, 41, True)
    drawPolyline(img, shapes, 42, 47, True)
    drawPolyline(img, shapes, 48, 59, True)
    drawPolyline(img, shapes, 60, 67, True)


def drawPolyline(img, shapes, start, end, isClosed=False):
    points = []
    for i in range(start, end + 1):
        point = [shapes.part(i).x, shapes.part(i).y]
        points.append(point)
    points = np.array(points, dtype=np.int32)
    cv2.polylines(img, [points], isClosed, (255, 80, 0),
                  thickness=1, lineType=cv2.LINE_8)


def pose_detection(source, path):
    detector = dlib.get_frontal_face_detector()
    predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")

    cap = cv2.VideoCapture(source)
    # fps = cap.get(cv2.CAP_PROP_FPS)
    # size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))
    # fourcc = cv2.VideoWriter_fourcc(*'MP4V')
    # videoWriter = cv2.VideoWriter('pose_result2.mp4', fourcc, fps, size, True)
    frame = 0
    best_right = 0
    best_left = 0
    while cap.isOpened():
        GAZE = "Face Not Found"
        ret, img = cap.read()
        frame += 1
        print('frame ------ ',frame)
        if not ret:
            print(f"[ERROR - System]Cannot read from source: {source}")
            break

        faces = detector(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), 0)

        face3Dmodel = ref3DModel()

        for face in faces:
            shape = predictor(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), face)

            # draw(img, shape)

            refImgPts = ref2dImagePoints(shape)

            height, width, channels = img.shape
            focalLength = 1 * width
            cameraMatrix = CameraMatrix(focalLength, (height / 2, width / 2))

            mdists = np.zeros((4, 1), dtype=np.float64)

            # calculate rotation and translation vector using solvePnP
            success, rotationVector, translationVector = cv2.solvePnP(
                face3Dmodel, refImgPts, cameraMatrix, mdists)

            rmat, jac = cv2.Rodrigues(rotationVector)
            angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)

            if angles[1] < -20:
                GAZE = "Left"
                print(GAZE)
                # if not os.path.exists(path + '/left.jpg'):
                if angles[1] < best_left:
                    print('better than last left')
                    best_left = angles[1]
                    cv2.imwrite(path + '/left.jpg', img)
            elif angles[1] > 20:
                GAZE = "Right"
                print(GAZE)
                if angles[1] > best_right:
                    print('better than last right ')
                    best_right = angles[1]
                    cv2.imwrite(path + '/right.jpg', img)
                # if not os.path.exists(path + '/right.jpg'):


            # elif angles[2] > 3:
            #     GAZE = "Looking Up"
            # elif angles[0] > -162:
            #     GAZE = "Looking Down"
            else:
                GAZE = "Forward"
                print(GAZE)
                if not os.path.exists(path + '/forward.jpg'):
                    cv2.imwrite(path + '/forward.jpg', img)
    cap.release()
    # videoWriter.release()
    cv2.destroyAllWindows()


def video_pose_detection (source):
    path = './GAZE'
    if os.path.exists(path + '/forward.jpg'):
        os.remove(path + '/forward.jpg')
    pose_detection(source, path)


